{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f2add1-9439-4f02-bbaa-edf718324d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb # Already imported, keeping for context if you still use LGBM later\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor # Make sure you have xgboost installed (pip install xgboost)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib # To save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402e2fbd-151a-4669-a99c-0beeeef17fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_tabular_only shape: (5952, 26)\n",
      "Loaded y_tabular_only shape: (5952,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_tabular_only = pd.read_csv('processed_diamond_features_X.csv')\n",
    "    y_tabular_only = pd.read_csv('diamond_target_y.csv').squeeze() # .squeeze() to ensure it's a Series\n",
    "    print(f\"Loaded X_tabular_only shape: {X_tabular_only.shape}\")\n",
    "    print(f\"Loaded y_tabular_only shape: {y_tabular_only.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: Tabular-only files not found. Ensure 'processed_diamond_features_X_tabular_only.csv' and 'diamond_target_y_tabular_only.csv' exist.\")\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d14f150-9258-4706-a018-c03bd700170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Fluorescence_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Shape_CUSHION</th>\n",
       "      <th>Shape_EMERALD</th>\n",
       "      <th>Shape_HEART</th>\n",
       "      <th>Shape_MARQUISE</th>\n",
       "      <th>Shape_OVAL</th>\n",
       "      <th>Shape_PEAR</th>\n",
       "      <th>Shape_RADIANT</th>\n",
       "      <th>Shape_ROUND</th>\n",
       "      <th>Colour_IsFancy_0</th>\n",
       "      <th>Colour_IsFancy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.151866</td>\n",
       "      <td>-0.630345</td>\n",
       "      <td>-0.264321</td>\n",
       "      <td>-0.218893</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.197973</td>\n",
       "      <td>-0.495109</td>\n",
       "      <td>-0.208121</td>\n",
       "      <td>0.345727</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120231</td>\n",
       "      <td>-0.248501</td>\n",
       "      <td>-0.418872</td>\n",
       "      <td>0.119879</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120231</td>\n",
       "      <td>-0.526929</td>\n",
       "      <td>-0.081671</td>\n",
       "      <td>0.368312</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120231</td>\n",
       "      <td>-0.184861</td>\n",
       "      <td>-0.362671</td>\n",
       "      <td>0.142464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight         X         Y         Z  Cut  Polish  Symmetry  Clarity  \\\n",
       "0 -0.151866 -0.630345 -0.264321 -0.218893  3.0     3.0       2.0      3.0   \n",
       "1  0.197973 -0.495109 -0.208121  0.345727  3.0     3.0       2.0      5.0   \n",
       "2  0.120231 -0.248501 -0.418872  0.119879  3.0     3.0       2.0      3.0   \n",
       "3  0.120231 -0.526929 -0.081671  0.368312  2.0     3.0       1.0      4.0   \n",
       "4  0.120231 -0.184861 -0.362671  0.142464  3.0     3.0       2.0      6.0   \n",
       "\n",
       "   Colour  Fluorescence_F  ...  Shape_CUSHION  Shape_EMERALD  Shape_HEART  \\\n",
       "0     7.0             0.0  ...            1.0            0.0          0.0   \n",
       "1     3.0             0.0  ...            1.0            0.0          0.0   \n",
       "2     7.0             1.0  ...            1.0            0.0          0.0   \n",
       "3     7.0             0.0  ...            1.0            0.0          0.0   \n",
       "4     7.0             1.0  ...            1.0            0.0          0.0   \n",
       "\n",
       "   Shape_MARQUISE  Shape_OVAL  Shape_PEAR  Shape_RADIANT  Shape_ROUND  \\\n",
       "0             0.0         0.0         0.0            0.0          0.0   \n",
       "1             0.0         0.0         0.0            0.0          0.0   \n",
       "2             0.0         0.0         0.0            0.0          0.0   \n",
       "3             0.0         0.0         0.0            0.0          0.0   \n",
       "4             0.0         0.0         0.0            0.0          0.0   \n",
       "\n",
       "   Colour_IsFancy_0  Colour_IsFancy_1  \n",
       "0               1.0               0.0  \n",
       "1               1.0               0.0  \n",
       "2               1.0               0.0  \n",
       "3               1.0               0.0  \n",
       "4               1.0               0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tabular_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b2462a-ba2e-4b44-9083-faef68f159a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Split Data into Training and Testing Sets ---\n",
      "X_train shape: (4761, 26)\n",
      "X_test shape: (1191, 26)\n",
      "y_train shape: (4761,)\n",
      "y_test shape: (1191,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 3: Split Data into Training and Testing Sets ---\")\n",
    "\n",
    "# Split the combined data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tabular_only, y_tabular_only, test_size=0.2, random_state=37 # 20% for testing, use random_state for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0a9305-dd5a-4514-bb62-cfdef03181b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Defining Models and Hyperparameter Grids ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Defining Models and Hyperparameter Grids ---\")\n",
    "param_grids = {\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [5, 20, None],\n",
    "        \"min_samples_split\": [2, 10],\n",
    "        \"min_samples_leaf\": [1, 5]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 200], # Added 200 as a common value\n",
    "        \"max_depth\": [10, None], # Added 20\n",
    "        \"min_samples_split\": [2, 10], # Added 10\n",
    "        \"min_samples_leaf\": [2, 4] # Added 4\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200, 300], # Adjusted values\n",
    "        \"learning_rate\": [0.01, 0.05, 0.2], # Adjusted values\n",
    "        \"max_depth\": [3, 5, 10], # Adjusted values\n",
    "        \"subsample\": [0.6, 0.8, 1.0], # Adjusted values\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0] # Added colsample_bytree for more comprehensive search\n",
    "    },\n",
    "    \"LightGBM\": { # Adding LightGBM as a candidate too!\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"num_leaves\": [31, 63, 127],\n",
    "        \"max_depth\": [-1, 7, 15], # -1 means no limit\n",
    "        \"reg_alpha\": [0, 0.1, 0.5],\n",
    "        \"reg_lambda\": [0, 0.1, 0.5]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=37),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=37),\n",
    "    \"XGBoost\": XGBRegressor(random_state=37, objective='reg:squarederror', eval_metric='rmse'), # Default objective for regression, eval_metric for consistency\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=37, objective='regression_l1') # Using MAE objective like before\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "evaluation_results = {} # To store test set results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04816d08-1bb0-4bbf-aece-dab02f27e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Performing Hyperparameter Tuning with RandomizedSearchCV ---\n",
      "\n",
      "Tuning Decision Tree...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for Decision Tree: {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 5}\n",
      "Best R2 score on validation sets for Decision Tree: 0.8376\n",
      "Test Set Evaluation for Decision Tree: RMSE = 604.15, R2 = 0.8571\n",
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for Random Forest: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n",
      "Best R2 score on validation sets for Random Forest: 0.8747\n",
      "Test Set Evaluation for Random Forest: RMSE = 460.00, R2 = 0.9172\n",
      "\n",
      "Tuning XGBoost...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for XGBoost: {'subsample': 0.6, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "Best R2 score on validation sets for XGBoost: 0.9037\n",
      "Test Set Evaluation for XGBoost: RMSE = 352.56, R2 = 0.9513\n",
      "\n",
      "Tuning LightGBM...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 874\n",
      "[LightGBM] [Info] Number of data points in the train set: 4761, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 1264.810059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for LightGBM: {'reg_lambda': 0.1, 'reg_alpha': 0.5, 'num_leaves': 127, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.2}\n",
      "Best R2 score on validation sets for LightGBM: 0.9053\n",
      "Test Set Evaluation for LightGBM: RMSE = 397.25, R2 = 0.9382\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Performing Hyperparameter Tuning with RandomizedSearchCV ---\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "    grid_search = RandomizedSearchCV(model, param_grids[model_name], cv=3, scoring='r2', n_jobs=-1, verbose=1, n_iter=10, random_state=37)\n",
    "\n",
    "    try:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best R2 score on validation sets for {model_name}: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        # Evaluate the best estimator on the test set\n",
    "        y_pred = best_models[model_name].predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        evaluation_results[model_name] = {'RMSE': rmse, 'R2': r2}\n",
    "        print(f\"Test Set Evaluation for {model_name}: RMSE = {rmse:.2f}, R2 = {r2:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error tuning {model_name}: {e}\")\n",
    "        print(\"Skipping this model and moving to the next.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b5fbd7-2bde-4598-9d5b-6436f8ff90e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Adding Linear Regression (No Hyperparameter Tuning) ---\n",
      "Test Set Evaluation for Linear Regression: RMSE = 671.33, R2 = 0.8236\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 5. Adding Linear Regression (No Hyperparameter Tuning) ---\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "best_models[\"Linear Regression\"] = lr\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "evaluation_results[\"Linear Regression\"] = {'RMSE': rmse_lr, 'R2': r2_lr}\n",
    "print(f\"Test Set Evaluation for Linear Regression: RMSE = {rmse_lr:.2f}, R2 = {r2_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6fae0d9-7d49-48a4-b385-ea09b52bbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f64156-615a-42ee-89a8-015644003039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 6. Implementing and Evaluating Stacking Regressor ---\n",
      "Starting Stacking Regressor training...\n",
      "Stacking Regressor training complete.\n",
      "Test Set Evaluation for Stacking Regressor: RMSE = 363.39, R2 = 0.9483\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 6. Implementing and Evaluating Stacking Regressor ---\")\n",
    "\n",
    "estimators = [\n",
    "    ('dt', best_models[\"Decision Tree\"]),\n",
    "    ('rf', best_models[\"Random Forest\"]),\n",
    "    ('xgb', best_models[\"XGBoost\"]),\n",
    "    ('lgbm', best_models[\"LightGBM\"])\n",
    "]\n",
    "\n",
    "final_estimator = Ridge(alpha=1.0)\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=final_estimator,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Stacking Regressor training...\")\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "print(\"Stacking Regressor training complete.\")\n",
    "\n",
    "y_pred_stack = stacking_regressor.predict(X_test)\n",
    "rmse_stack = np.sqrt(mean_squared_error(y_test, y_pred_stack))\n",
    "r2_stack = r2_score(y_test, y_pred_stack)\n",
    "\n",
    "best_models[\"Stacking Regressor\"] = stacking_regressor\n",
    "evaluation_results[\"Stacking Regressor\"] = {'RMSE': rmse_stack, 'R2': r2_stack}\n",
    "print(f\"Test Set Evaluation for Stacking Regressor: RMSE = {rmse_stack:.2f}, R2 = {r2_stack:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60506f6e-d0f8-4088-a40f-d086652c171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2XIN\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam # Using Adam optimizer\n",
    "from keras.callbacks import EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4939ead4-c7ba-42d6-bdfb-6f6b1ed5b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 7. Implementing and Evaluating Deep Neural Network (DNN) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2XIN\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,912</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m6,912\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,129</span> (188.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,129\u001b[0m (188.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,129</span> (188.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,129\u001b[0m (188.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting DNN model training...\n",
      "Epoch 1/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4891626.5000 - mae: 1408.4932 - root_mean_squared_error: 2187.7485 - val_loss: 1903812.8750 - val_mae: 546.5878 - val_root_mean_squared_error: 1379.7872\n",
      "Epoch 2/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1389782.7500 - mae: 518.2339 - root_mean_squared_error: 1172.9293 - val_loss: 766638.0625 - val_mae: 357.9086 - val_root_mean_squared_error: 875.5787\n",
      "Epoch 3/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 845584.7500 - mae: 428.6539 - root_mean_squared_error: 917.7016 - val_loss: 515574.0625 - val_mae: 309.1140 - val_root_mean_squared_error: 718.0349\n",
      "Epoch 4/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 591727.5000 - mae: 385.3958 - root_mean_squared_error: 768.2875 - val_loss: 449923.5938 - val_mae: 310.1934 - val_root_mean_squared_error: 670.7634\n",
      "Epoch 5/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 570995.9375 - mae: 361.7336 - root_mean_squared_error: 752.3968 - val_loss: 375060.4688 - val_mae: 293.6071 - val_root_mean_squared_error: 612.4218\n",
      "Epoch 6/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 488852.2812 - mae: 368.3344 - root_mean_squared_error: 698.4890 - val_loss: 347531.5625 - val_mae: 288.3871 - val_root_mean_squared_error: 589.5181\n",
      "Epoch 7/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451672.2500 - mae: 355.7484 - root_mean_squared_error: 670.8712 - val_loss: 374238.9375 - val_mae: 317.7447 - val_root_mean_squared_error: 611.7507\n",
      "Epoch 8/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479832.9375 - mae: 372.3169 - root_mean_squared_error: 691.1014 - val_loss: 317244.4688 - val_mae: 250.7910 - val_root_mean_squared_error: 563.2446\n",
      "Epoch 9/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472970.0312 - mae: 353.4626 - root_mean_squared_error: 684.1685 - val_loss: 318519.0000 - val_mae: 258.3419 - val_root_mean_squared_error: 564.3749\n",
      "Epoch 10/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457939.9688 - mae: 345.3103 - root_mean_squared_error: 673.9437 - val_loss: 315312.8750 - val_mae: 260.4830 - val_root_mean_squared_error: 561.5273\n",
      "Epoch 11/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508942.9375 - mae: 351.9553 - root_mean_squared_error: 710.0337 - val_loss: 316134.4062 - val_mae: 242.1051 - val_root_mean_squared_error: 562.2583\n",
      "Epoch 12/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436739.5312 - mae: 346.3211 - root_mean_squared_error: 660.1921 - val_loss: 306172.4688 - val_mae: 253.3114 - val_root_mean_squared_error: 553.3286\n",
      "Epoch 13/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 473630.4375 - mae: 346.3411 - root_mean_squared_error: 685.8317 - val_loss: 290720.6250 - val_mae: 233.7037 - val_root_mean_squared_error: 539.1851\n",
      "Epoch 14/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 524097.8750 - mae: 356.4440 - root_mean_squared_error: 721.4589 - val_loss: 305640.7188 - val_mae: 243.9347 - val_root_mean_squared_error: 552.8478\n",
      "Epoch 15/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 521380.6562 - mae: 345.0689 - root_mean_squared_error: 716.6573 - val_loss: 277380.1875 - val_mae: 232.8668 - val_root_mean_squared_error: 526.6689\n",
      "Epoch 16/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 490292.9688 - mae: 347.2485 - root_mean_squared_error: 692.0587 - val_loss: 283360.6875 - val_mae: 262.3332 - val_root_mean_squared_error: 532.3163\n",
      "Epoch 17/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418439.1562 - mae: 336.4698 - root_mean_squared_error: 645.2480 - val_loss: 277752.0625 - val_mae: 237.4159 - val_root_mean_squared_error: 527.0219\n",
      "Epoch 18/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448182.4688 - mae: 338.5990 - root_mean_squared_error: 668.5957 - val_loss: 274734.2500 - val_mae: 225.3084 - val_root_mean_squared_error: 524.1510\n",
      "Epoch 19/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461642.1875 - mae: 336.9641 - root_mean_squared_error: 678.0408 - val_loss: 306748.4062 - val_mae: 246.2727 - val_root_mean_squared_error: 553.8487\n",
      "Epoch 20/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 471394.0312 - mae: 343.0565 - root_mean_squared_error: 683.4650 - val_loss: 263281.2188 - val_mae: 208.9664 - val_root_mean_squared_error: 513.1094\n",
      "Epoch 21/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450505.6562 - mae: 335.2827 - root_mean_squared_error: 668.5486 - val_loss: 311715.8750 - val_mae: 222.5631 - val_root_mean_squared_error: 558.3152\n",
      "Epoch 22/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459684.2188 - mae: 333.5137 - root_mean_squared_error: 676.9609 - val_loss: 266977.8438 - val_mae: 233.9037 - val_root_mean_squared_error: 516.6990\n",
      "Epoch 23/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436533.6875 - mae: 335.2245 - root_mean_squared_error: 657.4554 - val_loss: 305089.6250 - val_mae: 215.3780 - val_root_mean_squared_error: 552.3492\n",
      "Epoch 24/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483785.7188 - mae: 345.7873 - root_mean_squared_error: 693.8981 - val_loss: 257266.4531 - val_mae: 204.6457 - val_root_mean_squared_error: 507.2144\n",
      "Epoch 25/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469752.8125 - mae: 337.0844 - root_mean_squared_error: 683.6293 - val_loss: 305046.7812 - val_mae: 238.0573 - val_root_mean_squared_error: 552.3104\n",
      "Epoch 26/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 497585.5312 - mae: 345.6310 - root_mean_squared_error: 698.1751 - val_loss: 365866.6250 - val_mae: 276.4497 - val_root_mean_squared_error: 604.8691\n",
      "Epoch 27/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541293.6250 - mae: 351.6747 - root_mean_squared_error: 725.9807 - val_loss: 264573.7812 - val_mae: 201.4590 - val_root_mean_squared_error: 514.3674\n",
      "Epoch 28/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371845.7500 - mae: 313.9495 - root_mean_squared_error: 598.3177 - val_loss: 256627.7969 - val_mae: 206.0555 - val_root_mean_squared_error: 506.5844\n",
      "Epoch 29/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393139.5625 - mae: 323.9347 - root_mean_squared_error: 625.7211 - val_loss: 249807.4531 - val_mae: 196.9081 - val_root_mean_squared_error: 499.8074\n",
      "Epoch 30/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401527.5312 - mae: 334.6605 - root_mean_squared_error: 631.3904 - val_loss: 279283.6250 - val_mae: 213.9478 - val_root_mean_squared_error: 528.4729\n",
      "Epoch 31/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415997.8750 - mae: 329.0945 - root_mean_squared_error: 643.1617 - val_loss: 274346.2500 - val_mae: 203.0112 - val_root_mean_squared_error: 523.7807\n",
      "Epoch 32/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356556.6875 - mae: 311.0647 - root_mean_squared_error: 592.8163 - val_loss: 271483.5312 - val_mae: 198.8696 - val_root_mean_squared_error: 521.0408\n",
      "Epoch 33/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480890.0000 - mae: 334.9256 - root_mean_squared_error: 690.9365 - val_loss: 247916.3281 - val_mae: 197.9894 - val_root_mean_squared_error: 497.9120\n",
      "Epoch 34/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511573.0625 - mae: 344.8190 - root_mean_squared_error: 713.9159 - val_loss: 273027.9062 - val_mae: 199.8714 - val_root_mean_squared_error: 522.5208\n",
      "Epoch 35/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469220.4688 - mae: 336.8900 - root_mean_squared_error: 682.9807 - val_loss: 245526.2188 - val_mae: 193.2260 - val_root_mean_squared_error: 495.5060\n",
      "Epoch 36/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406648.5938 - mae: 325.5930 - root_mean_squared_error: 634.8684 - val_loss: 267970.0625 - val_mae: 206.5266 - val_root_mean_squared_error: 517.6583\n",
      "Epoch 37/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377160.0312 - mae: 319.3013 - root_mean_squared_error: 612.8726 - val_loss: 278118.8125 - val_mae: 209.8789 - val_root_mean_squared_error: 527.3697\n",
      "Epoch 38/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444102.1250 - mae: 334.5012 - root_mean_squared_error: 665.6785 - val_loss: 280628.6875 - val_mae: 218.3761 - val_root_mean_squared_error: 529.7440\n",
      "Epoch 39/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391080.5625 - mae: 323.9293 - root_mean_squared_error: 621.7402 - val_loss: 259734.5156 - val_mae: 193.0942 - val_root_mean_squared_error: 509.6416\n",
      "Epoch 40/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399851.2812 - mae: 316.6740 - root_mean_squared_error: 629.1797 - val_loss: 251566.2344 - val_mae: 198.0042 - val_root_mean_squared_error: 501.5638\n",
      "Epoch 41/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416739.4375 - mae: 329.7374 - root_mean_squared_error: 643.0214 - val_loss: 261437.2344 - val_mae: 196.1623 - val_root_mean_squared_error: 511.3093\n",
      "Epoch 42/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418443.8750 - mae: 325.4157 - root_mean_squared_error: 644.9008 - val_loss: 251144.7812 - val_mae: 197.5651 - val_root_mean_squared_error: 501.1435\n",
      "Epoch 43/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495559.7812 - mae: 334.3412 - root_mean_squared_error: 699.7015 - val_loss: 258641.3594 - val_mae: 189.5903 - val_root_mean_squared_error: 508.5680\n",
      "Epoch 44/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421525.3438 - mae: 325.3471 - root_mean_squared_error: 644.2763 - val_loss: 258813.4688 - val_mae: 190.8741 - val_root_mean_squared_error: 508.7371\n",
      "Epoch 45/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393138.1875 - mae: 323.0464 - root_mean_squared_error: 625.6283 - val_loss: 244731.5625 - val_mae: 194.9793 - val_root_mean_squared_error: 494.7035\n",
      "Epoch 46/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384526.2500 - mae: 316.5417 - root_mean_squared_error: 618.1244 - val_loss: 250254.0312 - val_mae: 195.1118 - val_root_mean_squared_error: 500.2540\n",
      "Epoch 47/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427229.9688 - mae: 333.1198 - root_mean_squared_error: 652.2007 - val_loss: 258448.5312 - val_mae: 201.5997 - val_root_mean_squared_error: 508.3783\n",
      "Epoch 48/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302606.4062 - mae: 307.0391 - root_mean_squared_error: 549.1608 - val_loss: 272346.7188 - val_mae: 199.7366 - val_root_mean_squared_error: 521.8685\n",
      "Epoch 49/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315963.8750 - mae: 307.6482 - root_mean_squared_error: 560.0295 - val_loss: 267922.5000 - val_mae: 193.5937 - val_root_mean_squared_error: 517.6123\n",
      "Epoch 50/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393872.9688 - mae: 316.5283 - root_mean_squared_error: 623.8897 - val_loss: 266342.1250 - val_mae: 192.4703 - val_root_mean_squared_error: 516.0834\n",
      "DNN model training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 7. Implementing and Evaluating Deep Neural Network (DNN) ---\")\n",
    "\n",
    "# Define the DNN model architecture\n",
    "def build_dnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        # Input layer and first hidden layer\n",
    "        Dense(256, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.4), # Dropout for regularization\n",
    "        # Second hidden layer\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        # Third hidden layer\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        # Output layer for regression (single neuron, no activation)\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    # Using Adam optimizer with a custom learning rate\n",
    "    # Loss: Mean Squared Error (MSE) is common for regression\n",
    "    # Metrics: RMSE and MAE (Mean Absolute Error) are good to monitor\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(), 'mae'])\n",
    "    return model\n",
    "\n",
    "# Get the input shape from our training data\n",
    "input_dim = X_train.shape[1]\n",
    "dnn_model = build_dnn_model(input_dim)\n",
    "\n",
    "# Print model summary\n",
    "dnn_model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',         # Metric to monitor (validation loss)\n",
    "    patience=3,                 # Number of epochs with no improvement after which training will be stopped\n",
    "    mode='min',                 # 'min' because we want to minimize the loss\n",
    "    restore_best_weights=True,  # Restores model weights from the epoch with the best value of the monitored metric.\n",
    "    verbose=1                   # Show messages when stopping\n",
    ")\n",
    "# --- End Early Stopping Callback ---\n",
    "\n",
    "# Train the DNN model\n",
    "print(\"\\nStarting DNN model training...\")\n",
    "# Using 50 epochs, a batch size of 32, and validating on the test set\n",
    "history = dnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1, # Show training progress\n",
    "    #callbacks = [early_stopping]\n",
    ")\n",
    "print(\"DNN model training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe32786d-6b61-4daf-b648-e232e4e87f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421665.5312 - mae: 317.7915 - root_mean_squared_error: 648.3856 - val_loss: 251833.5312 - val_mae: 192.4664 - val_root_mean_squared_error: 501.8302\n",
      "Epoch 2/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325189.8438 - mae: 308.7541 - root_mean_squared_error: 568.4695 - val_loss: 258557.2812 - val_mae: 208.0235 - val_root_mean_squared_error: 508.4853\n",
      "Epoch 3/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413472.6250 - mae: 326.1227 - root_mean_squared_error: 640.3846 - val_loss: 277777.8438 - val_mae: 206.3626 - val_root_mean_squared_error: 527.0463\n",
      "Epoch 4/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324448.2188 - mae: 305.2728 - root_mean_squared_error: 565.0142 - val_loss: 252354.7344 - val_mae: 204.7196 - val_root_mean_squared_error: 502.3492\n",
      "Epoch 5/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408118.5625 - mae: 320.7172 - root_mean_squared_error: 637.6122 - val_loss: 271856.9375 - val_mae: 213.7290 - val_root_mean_squared_error: 521.3990\n",
      "Epoch 6/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371615.0938 - mae: 312.5207 - root_mean_squared_error: 607.2765 - val_loss: 255237.7812 - val_mae: 202.3298 - val_root_mean_squared_error: 505.2106\n",
      "Epoch 7/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422719.0312 - mae: 311.7640 - root_mean_squared_error: 645.0129 - val_loss: 269419.1562 - val_mae: 196.2282 - val_root_mean_squared_error: 519.0560\n",
      "Epoch 8/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387536.6875 - mae: 318.7697 - root_mean_squared_error: 620.7224 - val_loss: 248191.3281 - val_mae: 186.8838 - val_root_mean_squared_error: 498.1880\n",
      "Epoch 9/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403451.0938 - mae: 318.5888 - root_mean_squared_error: 634.2585 - val_loss: 250001.9219 - val_mae: 184.9660 - val_root_mean_squared_error: 500.0019\n",
      "Epoch 10/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304837.5938 - mae: 301.8492 - root_mean_squared_error: 551.4032 - val_loss: 263742.3125 - val_mae: 215.4443 - val_root_mean_squared_error: 513.5585\n",
      "Epoch 11/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417023.3438 - mae: 323.8614 - root_mean_squared_error: 644.1102 - val_loss: 263597.6250 - val_mae: 201.0365 - val_root_mean_squared_error: 513.4176\n",
      "Epoch 12/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377464.5312 - mae: 307.9335 - root_mean_squared_error: 610.5042 - val_loss: 262219.5312 - val_mae: 209.3595 - val_root_mean_squared_error: 512.0737\n",
      "Epoch 13/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410102.7812 - mae: 316.6531 - root_mean_squared_error: 635.2072 - val_loss: 269001.5000 - val_mae: 206.2001 - val_root_mean_squared_error: 518.6536\n",
      "Epoch 14/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391141.7500 - mae: 309.2493 - root_mean_squared_error: 619.2488 - val_loss: 246776.2656 - val_mae: 183.9086 - val_root_mean_squared_error: 496.7658\n",
      "Epoch 15/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433280.0625 - mae: 318.4797 - root_mean_squared_error: 656.6628 - val_loss: 248220.3438 - val_mae: 186.7023 - val_root_mean_squared_error: 498.2172\n",
      "Epoch 16/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361366.7812 - mae: 309.6336 - root_mean_squared_error: 599.2322 - val_loss: 315723.7812 - val_mae: 207.4359 - val_root_mean_squared_error: 561.8930\n",
      "Epoch 17/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315491.7812 - mae: 301.3571 - root_mean_squared_error: 558.4639 - val_loss: 251269.4062 - val_mae: 197.9036 - val_root_mean_squared_error: 501.2678\n",
      "Epoch 18/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273904.7812 - mae: 288.8531 - root_mean_squared_error: 520.8778 - val_loss: 248543.8125 - val_mae: 184.4751 - val_root_mean_squared_error: 498.5417\n",
      "Epoch 19/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409282.0312 - mae: 311.0457 - root_mean_squared_error: 636.9140 - val_loss: 252791.8594 - val_mae: 189.7992 - val_root_mean_squared_error: 502.7841\n",
      "Epoch 20/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324558.5938 - mae: 300.0985 - root_mean_squared_error: 568.0709 - val_loss: 256716.2188 - val_mae: 186.7287 - val_root_mean_squared_error: 506.6717\n",
      "Epoch 21/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 476263.0312 - mae: 314.3157 - root_mean_squared_error: 680.4582 - val_loss: 255903.5625 - val_mae: 194.7907 - val_root_mean_squared_error: 505.8691\n",
      "Epoch 22/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385733.6250 - mae: 312.5667 - root_mean_squared_error: 619.3679 - val_loss: 275438.1250 - val_mae: 195.9145 - val_root_mean_squared_error: 524.8220\n",
      "Epoch 23/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307892.6250 - mae: 299.1654 - root_mean_squared_error: 553.9413 - val_loss: 314538.5000 - val_mae: 288.6857 - val_root_mean_squared_error: 560.8373\n",
      "Epoch 24/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393445.0312 - mae: 314.6958 - root_mean_squared_error: 620.6396 - val_loss: 250838.9219 - val_mae: 185.3950 - val_root_mean_squared_error: 500.8382\n",
      "Epoch 25/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348412.0625 - mae: 306.9133 - root_mean_squared_error: 588.3896 - val_loss: 267508.1875 - val_mae: 187.9397 - val_root_mean_squared_error: 517.2119\n",
      "Epoch 26/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447673.0000 - mae: 312.0883 - root_mean_squared_error: 666.8116 - val_loss: 264905.8750 - val_mae: 193.6719 - val_root_mean_squared_error: 514.6901\n",
      "Epoch 27/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377465.1875 - mae: 311.8025 - root_mean_squared_error: 612.8907 - val_loss: 256763.0000 - val_mae: 199.7139 - val_root_mean_squared_error: 506.7179\n",
      "Epoch 28/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 350877.6875 - mae: 300.1428 - root_mean_squared_error: 591.0996 - val_loss: 259346.4531 - val_mae: 204.5521 - val_root_mean_squared_error: 509.2607\n",
      "Epoch 29/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 339704.8750 - mae: 293.4396 - root_mean_squared_error: 580.6459 - val_loss: 257095.8750 - val_mae: 191.2162 - val_root_mean_squared_error: 507.0462\n",
      "Epoch 30/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305031.4062 - mae: 295.4100 - root_mean_squared_error: 550.0092 - val_loss: 249231.6094 - val_mae: 184.8022 - val_root_mean_squared_error: 499.2310\n",
      "Epoch 31/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393298.6250 - mae: 316.9965 - root_mean_squared_error: 623.5244 - val_loss: 257993.3750 - val_mae: 184.8951 - val_root_mean_squared_error: 507.9305\n",
      "Epoch 32/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320713.4062 - mae: 301.3041 - root_mean_squared_error: 564.4364 - val_loss: 254150.3438 - val_mae: 188.7797 - val_root_mean_squared_error: 504.1333\n",
      "Epoch 33/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317097.5000 - mae: 296.4622 - root_mean_squared_error: 560.4896 - val_loss: 264710.1875 - val_mae: 204.3565 - val_root_mean_squared_error: 514.4999\n",
      "Epoch 34/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352078.6250 - mae: 296.8968 - root_mean_squared_error: 592.1794 - val_loss: 260673.3750 - val_mae: 185.9945 - val_root_mean_squared_error: 510.5618\n",
      "Epoch 35/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314048.5938 - mae: 303.0196 - root_mean_squared_error: 558.4363 - val_loss: 308673.8750 - val_mae: 285.1898 - val_root_mean_squared_error: 555.5843\n",
      "Epoch 36/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344958.5625 - mae: 302.7349 - root_mean_squared_error: 585.3625 - val_loss: 263065.6875 - val_mae: 193.1570 - val_root_mean_squared_error: 512.8993\n",
      "Epoch 37/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394935.3438 - mae: 312.6252 - root_mean_squared_error: 626.5799 - val_loss: 251277.6562 - val_mae: 190.6682 - val_root_mean_squared_error: 501.2760\n",
      "Epoch 38/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336745.8125 - mae: 307.8781 - root_mean_squared_error: 579.3948 - val_loss: 247884.1250 - val_mae: 182.3497 - val_root_mean_squared_error: 497.8796\n",
      "Epoch 39/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377001.5000 - mae: 309.7088 - root_mean_squared_error: 613.4628 - val_loss: 259085.8125 - val_mae: 191.6617 - val_root_mean_squared_error: 509.0047\n",
      "Epoch 40/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285438.5312 - mae: 284.8392 - root_mean_squared_error: 532.0007 - val_loss: 248138.9688 - val_mae: 189.0602 - val_root_mean_squared_error: 498.1355\n",
      "Epoch 41/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477351.0625 - mae: 316.4099 - root_mean_squared_error: 685.8695 - val_loss: 288832.3438 - val_mae: 249.8945 - val_root_mean_squared_error: 537.4313\n",
      "Epoch 42/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355268.3438 - mae: 309.0421 - root_mean_squared_error: 594.0528 - val_loss: 248234.1875 - val_mae: 183.4686 - val_root_mean_squared_error: 498.2310\n",
      "Epoch 43/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370869.4062 - mae: 296.7951 - root_mean_squared_error: 603.0536 - val_loss: 249008.3906 - val_mae: 187.9323 - val_root_mean_squared_error: 499.0074\n",
      "Epoch 44/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388993.4688 - mae: 296.7358 - root_mean_squared_error: 620.9585 - val_loss: 273260.5625 - val_mae: 185.6651 - val_root_mean_squared_error: 522.7433\n",
      "Epoch 45/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 327089.6562 - mae: 294.4587 - root_mean_squared_error: 570.1030 - val_loss: 352365.0625 - val_mae: 315.1013 - val_root_mean_squared_error: 593.6035\n",
      "Epoch 46/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344909.3438 - mae: 299.4492 - root_mean_squared_error: 583.0414 - val_loss: 296003.3750 - val_mae: 291.9530 - val_root_mean_squared_error: 544.0620\n",
      "Epoch 47/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312954.3438 - mae: 299.7021 - root_mean_squared_error: 558.3782 - val_loss: 314984.4062 - val_mae: 223.5319 - val_root_mean_squared_error: 561.2347\n",
      "Epoch 48/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 467819.7812 - mae: 316.4754 - root_mean_squared_error: 678.9382 - val_loss: 252737.8594 - val_mae: 185.8342 - val_root_mean_squared_error: 502.7304\n",
      "Epoch 49/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392289.5625 - mae: 295.7489 - root_mean_squared_error: 623.3862 - val_loss: 295120.0000 - val_mae: 194.0877 - val_root_mean_squared_error: 543.2495\n",
      "Epoch 50/50\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358061.2500 - mae: 302.3338 - root_mean_squared_error: 597.8678 - val_loss: 264942.8125 - val_mae: 192.1084 - val_root_mean_squared_error: 514.7260\n",
      "DNN model training complete.\n",
      "\n",
      "Evaluating DNN model on test set...\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Set Evaluation for Deep Neural Network: RMSE = 514.73, R2 = 0.8963, MAE = 192.11\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history = dnn_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=1, # Show training progress\n",
    "        #callbacks = [early_stopping]\n",
    "    )\n",
    "    print(\"DNN model training complete.\")\n",
    "\n",
    "    print(\"\\nEvaluating DNN model on test set...\")\n",
    "    dnn_eval_results = dnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "    dnn_loss = dnn_eval_results[0]\n",
    "    dnn_rmse = dnn_eval_results[1]\n",
    "    dnn_mae = dnn_eval_results[2]\n",
    "\n",
    "    y_pred_dnn = dnn_model.predict(X_test).flatten()\n",
    "    r2_dnn = r2_score(y_test, y_pred_dnn)\n",
    "\n",
    "    best_models[\"Deep Neural Network\"] = dnn_model\n",
    "    evaluation_results[\"Deep Neural Network\"] = {'RMSE': dnn_rmse, 'R2': r2_dnn, 'MAE': dnn_mae}\n",
    "    print(f\"Test Set Evaluation for Deep Neural Network: RMSE = {dnn_rmse:.2f}, R2 = {r2_dnn:.4f}, MAE = {dnn_mae:.2f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error training DNN: {e}\")\n",
    "    print(\"Skipping DNN model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf748b6-8607-4967-96ae-491e4de782cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 8. Summary of All Best Models and Test Set Performance ---\n",
      "Model: XGBoost\n",
      "  RMSE: 352.56\n",
      "  R2: 0.9513\n",
      "---\n",
      "Model: Stacking Regressor\n",
      "  RMSE: 363.39\n",
      "  R2: 0.9483\n",
      "---\n",
      "Model: LightGBM\n",
      "  RMSE: 397.25\n",
      "  R2: 0.9382\n",
      "---\n",
      "Model: Random Forest\n",
      "  RMSE: 460.00\n",
      "  R2: 0.9172\n",
      "---\n",
      "Model: Deep Neural Network\n",
      "  RMSE: 514.73\n",
      "  R2: 0.8963\n",
      "  MAE: 192.11\n",
      "---\n",
      "Model: Decision Tree\n",
      "  RMSE: 604.15\n",
      "  R2: 0.8571\n",
      "---\n",
      "Model: Linear Regression\n",
      "  RMSE: 671.33\n",
      "  R2: 0.8236\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 8. Summary of All Best Models and Test Set Performance ---\")\n",
    "sorted_results = sorted(evaluation_results.items(), key=lambda item: item[1]['R2'], reverse=True)\n",
    "\n",
    "for model_name, metrics in sorted_results:\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  RMSE: {metrics['RMSE']:.2f}\")\n",
    "    print(f\"  R2: {metrics['R2']:.4f}\")\n",
    "    if 'MAE' in metrics:\n",
    "        print(f\"  MAE: {metrics['MAE']:.2f}\")\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7938b16c-9fb2-4a43-b3fb-4348ef72247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 9. Saving Only the XGBoost Model ---\n",
      "Successfully saved XGBoost model to: Tabular_XGBoost_model.joblib\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 9. Saving Only the XGBoost Model ---\")\n",
    "\n",
    "model_name_to_save = \"XGBoost\"\n",
    "\n",
    "if model_name_to_save in best_models:\n",
    "    xgboost_model = best_models[model_name_to_save]\n",
    "    safe_model_name = model_name_to_save.replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    model_filename = f\"Tabular_{safe_model_name}_model.joblib\"\n",
    "\n",
    "    try:\n",
    "        joblib.dump(xgboost_model, model_filename)\n",
    "        print(f\"Successfully saved {model_name_to_save} model to: {model_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {model_name_to_save} model: {e}\")\n",
    "else:\n",
    "    print(f\"Error: {model_name_to_save} model not found in best_models. Make sure it was trained successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da7ac19-9e31-453f-bd40-18073799f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn version: 1.6.1\n",
      "TensorFlow version: 2.19.0\n",
      "NumPy version: 2.2.5\n",
      "Pandas version: 2.2.3\n",
      "XGBoost version: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Scikit-learn version:\", sklearn.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import numpy\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "\n",
    "import pandas\n",
    "print(\"Pandas version:\", pandas.__version__)\n",
    "\n",
    "import xgboost\n",
    "print(\"XGBoost version:\", xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389686c-d4d9-4276-98d0-74b877e1cfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_ENV",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
